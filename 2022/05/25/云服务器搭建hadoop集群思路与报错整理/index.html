<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>云服务器搭建hadoop集群思路与报错整理 | QiHang</title><meta name="keywords" content="大数据,hadoop,服务器集群,linux"><meta name="author" content="duanqihang"><meta name="copyright" content="duanqihang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="云服务器搭建hadoop集群思路与报错整理我的版本：hadoop：3.2.3      jdk: 11   centOS：7.6 建议在配置之前全部打一个快照方便出错搞混或者解决不了时回滚！为了避免后续启动集群各种各样连接超时，连接错误，禁止访问等问题，需在云服务器商提供的控制台开放所有端口。 大纲  创建hadoop用户与程序准备 创建hadoop用户与主机名配置 配置ssh免密登录 xsync">
<meta property="og:type" content="article">
<meta property="og:title" content="云服务器搭建hadoop集群思路与报错整理">
<meta property="og:url" content="http://knight1527.github.io/2022/05/25/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BAhadoop%E9%9B%86%E7%BE%A4%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%8A%A5%E9%94%99%E6%95%B4%E7%90%86/index.html">
<meta property="og:site_name" content="QiHang">
<meta property="og:description" content="云服务器搭建hadoop集群思路与报错整理我的版本：hadoop：3.2.3      jdk: 11   centOS：7.6 建议在配置之前全部打一个快照方便出错搞混或者解决不了时回滚！为了避免后续启动集群各种各样连接超时，连接错误，禁止访问等问题，需在云服务器商提供的控制台开放所有端口。 大纲  创建hadoop用户与程序准备 创建hadoop用户与主机名配置 配置ssh免密登录 xsync">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://knight1527.github.io/2022/05/25/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BAhadoop%E9%9B%86%E7%BE%A4%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%8A%A5%E9%94%99%E6%95%B4%E7%90%86/hadoop.png">
<meta property="article:published_time" content="2022-05-25T09:59:39.000Z">
<meta property="article:modified_time" content="2022-06-02T03:46:29.018Z">
<meta property="article:author" content="duanqihang">
<meta property="article:tag" content="大数据">
<meta property="article:tag" content="hadoop">
<meta property="article:tag" content="服务器集群">
<meta property="article:tag" content="linux">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://knight1527.github.io/2022/05/25/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BAhadoop%E9%9B%86%E7%BE%A4%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%8A%A5%E9%94%99%E6%95%B4%E7%90%86/hadoop.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://knight1527.github.io/2022/05/25/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BAhadoop%E9%9B%86%E7%BE%A4%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%8A%A5%E9%94%99%E6%95%B4%E7%90%86/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="/pluginsSrc/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="/pluginsSrc/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: '/pluginsSrc/flickr-justified-gallery/dist/fjGallery.min.js',
      css: '/pluginsSrc/flickr-justified-gallery/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '云服务器搭建hadoop集群思路与报错整理',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-06-02 11:46:29'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/media/myself.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">10</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">12</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> Messageboard</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/2022/05/25/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BAhadoop%E9%9B%86%E7%BE%A4%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%8A%A5%E9%94%99%E6%95%B4%E7%90%86/hadoop.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">QiHang</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> Messageboard</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">云服务器搭建hadoop集群思路与报错整理</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-05-25T09:59:39.000Z" title="Created 2022-05-25 17:59:39">2022-05-25</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-06-02T03:46:29.018Z" title="Updated 2022-06-02 11:46:29">2022-06-02</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/">环境搭建</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/linux%E5%AD%A6%E4%B9%A0/">linux学习</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="云服务器搭建hadoop集群思路与报错整理"><a href="#云服务器搭建hadoop集群思路与报错整理" class="headerlink" title="云服务器搭建hadoop集群思路与报错整理"></a>云服务器搭建hadoop集群思路与报错整理</h1><p>我的版本：hadoop：3.2.3      jdk: 11   centOS：7.6</p>
<p>建议在配置之前全部打一个快照方便出错搞混或者解决不了时回滚！为了避免后续启动集群各种各样连接超时，连接错误，禁止访问等问题，需在云服务器商提供的控制台开放所有端口。</p>
<p><strong>大纲</strong></p>
<ul>
<li><a href="#h1">创建hadoop用户与程序准备</a><ul>
<li><a href="#h-1">创建hadoop用户与主机名配置</a></li>
<li><a href="#h1-2">配置ssh免密登录</a></li>
<li><a href="#h1-3">xsync文件分发脚本（尚硅谷）</a></li>
</ul>
</li>
<li><a href="#h2">安装jdk</a></li>
<li><a href="#h3">安装hadoop</a></li>
<li><a href="#h4">集群配置</a></li>
<li><a href="#h5">集群启动</a></li>
<li><a href="#h6">报错与处理办法</a></li>
</ul>
<h2 id="h1">创建hadoop用户与程序准备</h2>

<h3 id="h1-1">创建hadoop用户与主机名配置</h3>

<p>我将使用三台云服务器搭建一个一主两从的服务器集群，搭建前先使用xshell或者其他连接工具连接上三台云服务器，选定一台配置较高的服务器当做主服务器（Master），（Master：2核4G，Slave1: 1核2G，Slave2：1核2G）。先配置Master在配置其他两台从机。</p>
<p>租服务器时不做设置登录上都是root用户，在xshell上执行命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">useradd -m hadoop -s /bin/bash   # 创建新用户hadoop</span><br></pre></td></tr></table></figure>
<p>修改hadoop用户密码，两遍确认</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">passwd hadoop      </span><br></pre></td></tr></table></figure>
<p>为hadoop用户增加管理员权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visudo</span><br></pre></td></tr></table></figure>
<p>编辑页面按下<code>:100</code>然后按下<code>i</code>在root那一行下添加一行<code>hadoop  ALL=(ALL)       ALL</code></p>
<p><img src="https://pic-home.oss-cn-beijing.aliyuncs.com/img/image-20220525183337888.png" alt="image-20220525183337888"></p>
<p><code>esc</code>然后<code>:wq</code>保存</p>
<p>在每一台机器创建hadoop用户</p>
<p><strong>配置主机名</strong></p>
<p>为了后续搭建集群和配置更简单直观，改一下主机名，并配置hosts文件。云服务器集群和虚拟机集群的hosts配置有所不同</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hostname   # 修改主机名</span><br></pre></td></tr></table></figure>
<p><img src="https://pic-home.oss-cn-beijing.aliyuncs.com/img/image-20220525184907212.png" alt="image-20220525184907212"></p>
<p><strong>注：</strong>主服务器改为Master，其他两台为Slave1和Slave2并且不能有空格</p>
<p>配置hosts文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hosts         # 注意每台机器的hosts都不一样</span><br></pre></td></tr></table></figure>
<p><strong>Master的hosts文件追加</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">内网ip  Master  Master</span><br><span class="line">外网ip  Slave1  Slave1</span><br><span class="line">外网ip  Slave2  Slave2</span><br></pre></td></tr></table></figure>
<p>内网ip可以通过<code>ifconfig</code>查看（如下192.168.0.4），外网ip即连接xshell的ip</p>
<p><img src="https://pic-home.oss-cn-beijing.aliyuncs.com/img/image-20220525185712355.png" alt="image-20220525185712355"></p>
<p>不能出现<code>127.0.0.1 Master</code>这样的记录</p>
<p><strong>Slave1上</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">内网ip  Slave1  Slave1</span><br><span class="line">外网ip  Master  Master</span><br><span class="line">外网ip  Slave2  Slave2</span><br></pre></td></tr></table></figure>
<p>其他从机同理</p>
<p><strong>重启三台云服务器</strong></p>
<p>重启后即可用xshell连接每台的hadoop用户</p>
<p><img src="https://pic-home.oss-cn-beijing.aliyuncs.com/img/image-20220525190341634.png" alt="image-20220525190341634"></p>
<p><strong>在每台机器上ping其他节点看是否成功</strong></p>
<p><img src="https://pic-home.oss-cn-beijing.aliyuncs.com/img/image-20220525190550081.png" alt="image-20220525190550081"></p>
<p>没ping通再检查一边配置或者重新配置。</p>
<h2 id="h1-2">配置ssh免密登录</h2>

<p>之后的操作默认都在hadoop用户下操作。</p>
<p>CentOS默认安装有SSH使用命令查看</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa | grep ssh</span><br></pre></td></tr></table></figure>
<p><img src="https://pic-home.oss-cn-beijing.aliyuncs.com/img/image-20220525192617321.png" alt="image-20220525192617321"></p>
<p>未安装执行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install openssh-clients</span><br><span class="line">sudo yum install openssh-server</span><br></pre></td></tr></table></figure>
<p>执行命令测试</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh localhost   # 如果可以登录 使用exit退出</span><br></pre></td></tr></table></figure>
<p>在Master节点生成公钥</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd ~/.ssh               # 如果没有该目录，先执行一次ssh localhost</span><br><span class="line">rm ./id_rsa*            # 删除之前生成的公匙（如果有）</span><br><span class="line">ssh-keygen -t rsa       # 一直按回车就可以</span><br></pre></td></tr></table></figure>
<p>让Master无密码ssh本机</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat ./id_rsa.pub &gt;&gt; ./authorized_keys  # 执行后使用 ssh Master 验证</span><br></pre></td></tr></table></figure>
<p>分发公钥给所有从节点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp ~/.ssh/id_rsa.pub hadoop@Slave1:/home/hadoop/  # 其他从节点同理</span><br></pre></td></tr></table></figure>
<p><strong>在从节点上将ssh公钥授权（Slave1为例）</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir ~/.ssh       # 如果不存在该文件夹需先创建，若已存在则忽略</span><br><span class="line">cat ~/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">rm ~/id_rsa.pub    # 用完就可以删掉了</span><br></pre></td></tr></table></figure>
<p>在Master上测试</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh Slave1   </span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果还是连不上，在每台从机上执行如下操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd ~/.ssh</span><br><span class="line">chmod 700 ../</span><br><span class="line">chmod 700 .</span><br><span class="line">chmod 600 authorized_keys</span><br></pre></td></tr></table></figure>
</blockquote>
<p><img src="https://pic-home.oss-cn-beijing.aliyuncs.com/img/image-20220525193633677.png" alt="image-20220525193633677"></p>
<h2 id="h1-3">xsync文件分发脚本（尚硅谷）</h2>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~/bin  # 如果提示找不到路径 先执行mkdir ~/bin再执行cd 命令</span><br><span class="line">vim xsync # 加入下面的脚本</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">1. 判断参数个数</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then </span><br><span class="line">	echo Not Enough Arguement</span><br><span class="line">	exit;</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">2. 遍历集群所有机器</span></span><br><span class="line">for host in Slave1 Slave2</span><br><span class="line">do </span><br><span class="line">	echo ===================== $host =====================</span><br><span class="line"><span class="meta prompt_">	#</span><span class="language-bash">3. 遍历所有目录，挨个发送</span></span><br><span class="line">	</span><br><span class="line">	for file in $@</span><br><span class="line">	do </span><br><span class="line"><span class="meta prompt_">		#</span><span class="language-bash">4. 判断文件是否存在</span></span><br><span class="line">		if [ -e $file ]</span><br><span class="line">			then </span><br><span class="line">				#5. 获取父目录</span><br><span class="line">				pdir=$(cd -p $(dirname $file); pwd)</span><br><span class="line">				</span><br><span class="line">				#6. 获取当前文件的名称</span><br><span class="line">				fname=$(basename $file)</span><br><span class="line">				ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line">				rsync -av $pdir/$fname $host:$pdir</span><br><span class="line">			else </span><br><span class="line">				echo $file does not exists!</span><br><span class="line">				</span><br><span class="line">		fi</span><br><span class="line">	done</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p>保存退出</p>
<p><strong>添加环境变量</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 xsync # 增加文件可执行权限</span><br><span class="line">vim ~/.bashrc # 添加一行 export PATH=$PATH:/home/hadoop/bi</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果想在root用户或者其他用户下也能使用，其他环境变量同理</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
</blockquote>
<p>验证</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd ~</span><br><span class="line">xsync bin # 向从节点发送bin目录</span><br><span class="line">ssh Slave1</span><br><span class="line">cd ~</span><br><span class="line">ll        # 如果看到bin目录就成功了</span><br><span class="line">exit</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果提示错误信息：<code>rsync common not found</code></p>
<p>执行如下操作：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install rsync -y </span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="h2">安装jdk</h2>

<p>下载地址：<a target="_blank" rel="noopener" href="https://www.oracle.com/java/technologies/downloads/#java11">oracle</a></p>
<p>在Master上</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local</span><br><span class="line">mkdir devtools  # 开发工具目录</span><br></pre></td></tr></table></figure>
<p>下载完成通过把xftp或者其他工具上传压缩包到<code>devtools</code>目录</p>
<p>解压：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -zvxf jdk-11.0.15.1_linux_bin.tar.gz</span><br></pre></td></tr></table></figure>
<p>添加环境变量(开发环境最好加到全局环境变量里面，所有用户都能使用)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile # 增加如下环境变量</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">JAVA Environment</span></span><br><span class="line">export JAVA_HOME=/usr/local/devtools/jdk-11.0.15.1</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"></span><br><span class="line">source /etc/profile # 使生效</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">验证</span></span><br><span class="line">java -version</span><br><span class="line">echo $JAVA_HOME</span><br></pre></td></tr></table></figure>
<p><strong>分发给所有节点</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local</span><br><span class="line">xsync devtools/   # 分发到节点</span><br></pre></td></tr></table></figure>
<p><strong>在所有从节点上配置JAVA环境变量并验证</strong></p>
<h2 id="h3">安装hadoop</h2>

<p>下载地址：<a target="_blank" rel="noopener" href="https://mirrors.cnnic.cn/apache/hadoop/common/">镜像站</a></p>
<p>Master上，上传压缩包到<code>/usr/local</code>目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cd /sur/local</span><br><span class="line">sudo tar -zxf hadoop-3.2.3.tar.gz  # 解压</span><br><span class="line">sudo mv ./hadoop-3.2.3/  /hadoop # 将文件夹改名</span><br><span class="line">sudo chown -R hadoop:hadoop ./hadoop # 修改文件权限</span><br><span class="line">vim ~/.bashrc # 修改环境变量,添加如下内容</span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop/</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br><span class="line"></span><br><span class="line">source ~/.bashrc # 别忘了source</span><br><span class="line">hadoop version# 验证是否安装成功</span><br></pre></td></tr></table></figure>
<p>分发：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local</span><br><span class="line">xsync hadoop/</span><br></pre></td></tr></table></figure>
<h2 id="h4">集群配置</h2>

<p>集群部署参考尚硅谷hadoop教程，如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">Master</th>
<th style="text-align:center">Slave1</th>
<th style="text-align:center">Slave2</th>
</tr>
</thead>
<tbody>
<tr>
<td>HDFS</td>
<td style="text-align:center">NameNode <br> DataNode</td>
<td style="text-align:center">DataNode</td>
<td style="text-align:center">SecondaryNameNode <br> DataNode</td>
</tr>
<tr>
<td>YARN</td>
<td style="text-align:center">NodeManager</td>
<td style="text-align:center">ResourceManager <br> NodeManager<br> JobHistoryServer</td>
<td style="text-align:center">NodeManager</td>
</tr>
<tr>
<td>SPARK</td>
<td style="text-align:center">Worker<br>HistoryServer</td>
<td style="text-align:center">Worker</td>
<td style="text-align:center">Worker</td>
</tr>
</tbody>
</table>
</div>
<p><strong>配置文件</strong></p>
<p>在Master上：</p>
<h3>workers</h3>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/local/hadoop/etc/hadoop/workers  # 添加内容如下</span><br></pre></td></tr></table></figure>
<p><img src="https://pic-home.oss-cn-beijing.aliyuncs.com/img/image-20220525211535417.png" alt="image-20220525211535417"></p>
<h3>core-site.xml</h3>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop/etc/hadoop</span><br><span class="line">vim core-site.xml</span><br></pre></td></tr></table></figure>
<p>在<code>&lt;configuration&gt;&lt;/configuration&gt;</code>中添加：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://Master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/hadoop/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3>hdfs-site.xml</h3>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop/etc/hadoop</span><br><span class="line">vim hadoop-env.sh  # 添加如下环境变量</span><br><span class="line">export JAVA_HOME=jdk安装目录</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hdfs-site.xml  # 添加如下</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定NameNode的webui端口 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定SecondaryNameNode的webui端口 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>Slave2:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3>yarn-site.xml</h3>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop/etc/hadoop</span><br><span class="line">vim yarn-env.sh</span><br><span class="line">export JAVA_HOME=jdk安装目录</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim yarn-site.xml   # 添加如下</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>Slave1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3>mapred-site.xml</h3>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop/etc/hadoop</span><br><span class="line">vim mapred-env.sh</span><br><span class="line">export JAVA_HOME=jdk安装目录</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim mapred-site-xml  # 添加如下</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定MR运行在Yarn上 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3>分发配置文件</h3>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop/etc</span><br><span class="line">xsync hadoop/</span><br></pre></td></tr></table></figure>
<h2 id="h5">集群启动</h2>

<p><strong>关闭每台服务器的防火墙：</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop firewalld  # 临时关闭防火墙</span><br><span class="line">sudo systemctl disable firewalld  # 防止重启后防火墙启动</span><br></pre></td></tr></table></figure>
<p>在Master上：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop</span><br><span class="line">hadoop namenode -format  # 如果集群没启动过则先执行此格式化再启动</span><br><span class="line">sbin/start-dfs.sh</span><br><span class="line">jps   # 查看启动进程情况</span><br></pre></td></tr></table></figure>
<p><img src="https://pic-home.oss-cn-beijing.aliyuncs.com/img/image-20220525204738989.png" alt="image-20220525204738989"></p>
<p><strong>注：</strong>因为我后续配置了Spark历史服务器的原因所以有HistoryServer进程</p>
<p>在Slave1上：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop</span><br><span class="line">sbin/start-yarn.sh</span><br><span class="line">jps  # 查看进程情况</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果报错permission denied 需要在Slave1上配置Master和Slave2的ssh登录，即在Slave1上生成公钥再在Master和Slave2上给公钥授权</p>
</blockquote>
<p><img src="https://pic-home.oss-cn-beijing.aliyuncs.com/img/image-20220525204859435.png" alt="image-20220525204859435"></p>
<p><strong>注：</strong>因为我后续配置了yarn历史服务器的原因所以有JobHistoryServer进程</p>
<p>在Slave2上：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps   # 查看hadoop进程</span><br></pre></td></tr></table></figure>
<p><img src="https://pic-home.oss-cn-beijing.aliyuncs.com/img/image-20220525204942832.png" alt="image-20220525204942832"></p>
<p>服务器进程开启情况和预期部署规划一致，证明没有什么问题。</p>
<p><strong>查看ui界面：</strong></p>
<p><strong>注：</strong>因为我在windows host文件添加了主机IP映射所以用<code>Master:9870</code>可以访问</p>
<p><strong>hdfs ui：</strong></p>
<p><img src="https://pic-home.oss-cn-beijing.aliyuncs.com/img/image-20220525205052308.png" alt="image-20220525205052308"></p>
<p><strong>yarn ui</strong></p>
<p><img src="https://pic-home.oss-cn-beijing.aliyuncs.com/img/image-20220525210153756.png" alt="image-20220525210153756"></p>
<p><strong>集群关闭</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop</span><br><span class="line">sbin/stop-yarn.sh # 在Slave1上关闭yarn</span><br><span class="line">sbin/stop-dfs.sh # 在Master上关闭hdfs</span><br></pre></td></tr></table></figure>
<h2 id="h6">报错与处理办法</h2>

<h3 id="NameNode启动一段时间就挂掉了（hdfs过一段时间就不能访问了）"><a href="#NameNode启动一段时间就挂掉了（hdfs过一段时间就不能访问了）" class="headerlink" title="NameNode启动一段时间就挂掉了（hdfs过一段时间就不能访问了）"></a>NameNode启动一段时间就挂掉了（hdfs过一段时间就不能访问了）</h3><p>jps查看进程信息，发现NameNode没了,cd到<code>/usr/local/hadoop/logs</code>找到namenode的日志查看发下报错信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM</span><br></pre></td></tr></table></figure>
<p>有以下几种可能解决办法：</p>
<h4 id="1"><a href="#1" class="headerlink" title="(1)"></a>(1)</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop</span><br><span class="line">sbin/hadoop-daemon.sh start namenode</span><br><span class="line">hadoop dfsadmin -refreshNodes</span><br></pre></td></tr></table></figure>
<h4 id="2"><a href="#2" class="headerlink" title="(2)"></a>(2)</h4><p>关闭集群，做如下配置，然后重启hadoop：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop/etc/hadoop</span><br><span class="line">vim hadoop-env.sh  # 添加如下内容,根据云服务器配置从上往下调，直到NameNode不会挂</span><br><span class="line"></span><br><span class="line">export HADOOP_HEAPSIZE_MAX=1000M</span><br><span class="line">export HADOOP_HEAPSIZE_MIN=100M</span><br><span class="line"></span><br><span class="line">xsync hadoop-env.sh</span><br></pre></td></tr></table></figure>
<h4 id="3"><a href="#3" class="headerlink" title="(3)"></a>(3)</h4><p>删除所有节点hadoop目录下的data和logs文件夹，重新进行格式化，启动集群。（没有办法的办法）不要轻易重新格式化因为这可能造成ID不一致，NameNode启动不了（到时候还得再重新格式化）。</p>
<h4 id="4-被病毒程序占用系统资源"><a href="#4-被病毒程序占用系统资源" class="headerlink" title="(4) 被病毒程序占用系统资源"></a>(4) 被病毒程序占用系统资源</h4><p>分析：经StackOverflow这是一个系统问题，并不是hadoop的错误，在hadoop运行过程中系统态cpu占用率太高被系统kill掉了，使用<code>top</code>命令查看cpu使用率一度到了96%，在关闭hadoop集群以后，top查看仍有hadoop用户的进程，并且cpu占用率还高达50%。这个进程kill掉后还会自启，并且pid还会改变。所以可以推断这是遭恶意攻击了。</p>
<p><strong>原因：</strong></p>
<p>可能是之前在用vpn看StackOverflow时，没关闭vpn的情况下直接用xshell连接过服务器导致ip暴露了</p>
<p><strong>解决：</strong></p>
<p>查询正在使用socket的此进程名的直接ip</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -anp | grep zapppp  # 通过top查看占用资源的进程COMMAND为zapppp</span><br></pre></td></tr></table></figure>
<p>经查，查询到的ip是国外的，禁掉ip</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -A INPUT -p tcp -s 目标ip -j DROP</span><br></pre></td></tr></table></figure>
<p>程序进程停了一段时间又重启了，关掉pam后门：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_40412037/article/details/118728788">Linux留后门</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum reinstall pam</span><br></pre></td></tr></table></figure>
<p>还是要自启，关闭定时服务，删除进程对应的目录：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">crontab -e        # 注释掉所有内容（每行前加一个#）</span><br><span class="line">ps aux | grep zapppp # 拿到pid</span><br><span class="line">ll /proc/pid    # 找到进程的绝对路径，如下</span><br><span class="line">cd /home/hadoop/.cache_....  </span><br><span class="line">ll              # 查看里面有可执行文件</span><br><span class="line">cd ..</span><br><span class="line">rm -rf .cache../  # 删除整个目录</span><br></pre></td></tr></table></figure>
<p>目前暂时没有出现那个进程了，cpu占用率也基本是百分之零点几。</p>
<h3 id="NameNode启动不了"><a href="#NameNode启动不了" class="headerlink" title="NameNode启动不了"></a>NameNode启动不了</h3><h4 id="Connection-time-out-Connection-refused"><a href="#Connection-time-out-Connection-refused" class="headerlink" title="Connection time out / Connection refused"></a>Connection time out / Connection refused</h4><p>关闭防火墙</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop firewalld  </span><br><span class="line">sudo systemctl disable firewalld </span><br></pre></td></tr></table></figure>
<h4 id="启动时报错hadoop0-ERROR-Cannot-set-priority-of-datanode-process-2518或者其他端口"><a href="#启动时报错hadoop0-ERROR-Cannot-set-priority-of-datanode-process-2518或者其他端口" class="headerlink" title="启动时报错hadoop0: ERROR: Cannot set priority of datanode process 2518或者其他端口"></a>启动时报错hadoop0: ERROR: Cannot set priority of datanode process 2518或者其他端口</h4><p>开启云服务器全部端口</p>
<h4 id="NameNode-DataNodeID不一致failed-to-start-namenode"><a href="#NameNode-DataNodeID不一致failed-to-start-namenode" class="headerlink" title="NameNode DataNodeID不一致failed to start namenode"></a>NameNode DataNodeID不一致failed to start namenode</h4><p>所有节点删除hadoop目录的tmp,data和logs文件夹，重新格式化，启动集群。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="http://knight1527.github.io">duanqihang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="mailto:qihang_duan@foxmail.com">mailto:qihang_duan@foxmail.com</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><a class="post-meta__tags" href="/tags/hadoop/">hadoop</a><a class="post-meta__tags" href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%9B%86%E7%BE%A4/">服务器集群</a><a class="post-meta__tags" href="/tags/linux/">linux</a></div><div class="post_share"><div class="social-share" data-image="/2022/05/25/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BAhadoop%E9%9B%86%E7%BE%A4%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%8A%A5%E9%94%99%E6%95%B4%E7%90%86/hadoop.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="/pluginsSrc/butterfly-extsrc/ShareJS/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="/pluginsSrc/butterfly-extsrc/ShareJS/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> Donate</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/06/02/hadoop%E6%95%B4%E5%90%88spark%E6%A1%86%E6%9E%B6/"><img class="prev-cover" src="/2022/06/02/hadoop%E6%95%B4%E5%90%88spark%E6%A1%86%E6%9E%B6/spark.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">hadoop整合spark框架</div></div></a></div><div class="next-post pull-right"><a href="/2022/05/08/2022%E4%B8%80%E5%AD%A3%E5%BA%A6%E6%80%BB%E7%BB%93/"><img class="next-cover" src="/2022/05/08/2022%E4%B8%80%E5%AD%A3%E5%BA%A6%E6%80%BB%E7%BB%93/doge.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">2022一季度总结</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2022/06/02/hadoop%E6%95%B4%E5%90%88spark%E6%A1%86%E6%9E%B6/" title="hadoop整合spark框架"><img class="cover" src="/2022/06/02/hadoop%E6%95%B4%E5%90%88spark%E6%A1%86%E6%9E%B6/spark.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-02</div><div class="title">hadoop整合spark框架</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/media/myself.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">duanqihang</div><div class="author-info__description">Technology changes the world. Code enriches our lives</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">10</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">12</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/knight1527?tab=repositories"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/knight1527?tab=repositories" target="_blank" title="Github"><i class="fa-brands fa-github-alt"></i></a><a class="social-icon" href="mailto:qihang_duan@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="http://wpa.qq.com/msgrd?v=3&amp;uin=1518607977&amp;site=qq&amp;menu=yes" target="_blank" title="QQ"><i class="fa-brands fa-qq"></i></a><a class="social-icon" href="https://gitee.com/qi_hang_duan/projects" target="_blank" title="Gitee"><i class="fa-brands fa-git"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">如果页面加载缓慢请移步至： http://qihangduan.icu</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BAhadoop%E9%9B%86%E7%BE%A4%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%8A%A5%E9%94%99%E6%95%B4%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">云服务器搭建hadoop集群思路与报错整理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#h1"><span class="toc-number">1.1.</span> <span class="toc-text">创建hadoop用户与程序准备</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#h1-1"><span class="toc-number">1.1.1.</span> <span class="toc-text">创建hadoop用户与主机名配置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#h1-2"><span class="toc-number">1.2.</span> <span class="toc-text">配置ssh免密登录</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#h1-3"><span class="toc-number">1.3.</span> <span class="toc-text">xsync文件分发脚本（尚硅谷）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#h2"><span class="toc-number">1.4.</span> <span class="toc-text">安装jdk</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#h3"><span class="toc-number">1.5.</span> <span class="toc-text">安装hadoop</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#h4"><span class="toc-number">1.6.</span> <span class="toc-text">集群配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">1.6.1.</span> <span class="toc-text">workers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">1.6.2.</span> <span class="toc-text">core-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">1.6.3.</span> <span class="toc-text">hdfs-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">1.6.4.</span> <span class="toc-text">yarn-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">1.6.5.</span> <span class="toc-text">mapred-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">1.6.6.</span> <span class="toc-text">分发配置文件</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#h5"><span class="toc-number">1.7.</span> <span class="toc-text">集群启动</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#h6"><span class="toc-number">1.8.</span> <span class="toc-text">报错与处理办法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#NameNode%E5%90%AF%E5%8A%A8%E4%B8%80%E6%AE%B5%E6%97%B6%E9%97%B4%E5%B0%B1%E6%8C%82%E6%8E%89%E4%BA%86%EF%BC%88hdfs%E8%BF%87%E4%B8%80%E6%AE%B5%E6%97%B6%E9%97%B4%E5%B0%B1%E4%B8%8D%E8%83%BD%E8%AE%BF%E9%97%AE%E4%BA%86%EF%BC%89"><span class="toc-number">1.8.1.</span> <span class="toc-text">NameNode启动一段时间就挂掉了（hdfs过一段时间就不能访问了）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1"><span class="toc-number">1.8.1.1.</span> <span class="toc-text">(1)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2"><span class="toc-number">1.8.1.2.</span> <span class="toc-text">(2)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3"><span class="toc-number">1.8.1.3.</span> <span class="toc-text">(3)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E8%A2%AB%E7%97%85%E6%AF%92%E7%A8%8B%E5%BA%8F%E5%8D%A0%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%B5%84%E6%BA%90"><span class="toc-number">1.8.1.4.</span> <span class="toc-text">(4) 被病毒程序占用系统资源</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NameNode%E5%90%AF%E5%8A%A8%E4%B8%8D%E4%BA%86"><span class="toc-number">1.8.2.</span> <span class="toc-text">NameNode启动不了</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Connection-time-out-Connection-refused"><span class="toc-number">1.8.2.1.</span> <span class="toc-text">Connection time out &#x2F; Connection refused</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E6%97%B6%E6%8A%A5%E9%94%99hadoop0-ERROR-Cannot-set-priority-of-datanode-process-2518%E6%88%96%E8%80%85%E5%85%B6%E4%BB%96%E7%AB%AF%E5%8F%A3"><span class="toc-number">1.8.2.2.</span> <span class="toc-text">启动时报错hadoop0: ERROR: Cannot set priority of datanode process 2518或者其他端口</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#NameNode-DataNodeID%E4%B8%8D%E4%B8%80%E8%87%B4failed-to-start-namenode"><span class="toc-number">1.8.2.3.</span> <span class="toc-text">NameNode DataNodeID不一致failed to start namenode</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/06/02/hadoop%E6%95%B4%E5%90%88spark%E6%A1%86%E6%9E%B6/" title="hadoop整合spark框架"><img src="/2022/06/02/hadoop%E6%95%B4%E5%90%88spark%E6%A1%86%E6%9E%B6/spark.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="hadoop整合spark框架"/></a><div class="content"><a class="title" href="/2022/06/02/hadoop%E6%95%B4%E5%90%88spark%E6%A1%86%E6%9E%B6/" title="hadoop整合spark框架">hadoop整合spark框架</a><time datetime="2022-06-02T02:59:25.000Z" title="Created 2022-06-02 10:59:25">2022-06-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/25/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BAhadoop%E9%9B%86%E7%BE%A4%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%8A%A5%E9%94%99%E6%95%B4%E7%90%86/" title="云服务器搭建hadoop集群思路与报错整理"><img src="/2022/05/25/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BAhadoop%E9%9B%86%E7%BE%A4%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%8A%A5%E9%94%99%E6%95%B4%E7%90%86/hadoop.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="云服务器搭建hadoop集群思路与报错整理"/></a><div class="content"><a class="title" href="/2022/05/25/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BAhadoop%E9%9B%86%E7%BE%A4%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%8A%A5%E9%94%99%E6%95%B4%E7%90%86/" title="云服务器搭建hadoop集群思路与报错整理">云服务器搭建hadoop集群思路与报错整理</a><time datetime="2022-05-25T09:59:39.000Z" title="Created 2022-05-25 17:59:39">2022-05-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/08/2022%E4%B8%80%E5%AD%A3%E5%BA%A6%E6%80%BB%E7%BB%93/" title="2022一季度总结"><img src="/2022/05/08/2022%E4%B8%80%E5%AD%A3%E5%BA%A6%E6%80%BB%E7%BB%93/doge.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2022一季度总结"/></a><div class="content"><a class="title" href="/2022/05/08/2022%E4%B8%80%E5%AD%A3%E5%BA%A6%E6%80%BB%E7%BB%93/" title="2022一季度总结">2022一季度总结</a><time datetime="2022-05-08T14:14:09.000Z" title="Created 2022-05-08 22:14:09">2022-05-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/04/01/%E8%93%9D%E6%A1%A5%E6%9D%AFB%E7%BB%84-%E4%BA%BA%E7%89%A9%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/" title="蓝桥杯B组_人物相关性分析"><img src="/media/las.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="蓝桥杯B组_人物相关性分析"/></a><div class="content"><a class="title" href="/2022/04/01/%E8%93%9D%E6%A1%A5%E6%9D%AFB%E7%BB%84-%E4%BA%BA%E7%89%A9%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/" title="蓝桥杯B组_人物相关性分析">蓝桥杯B组_人物相关性分析</a><time datetime="2022-04-01T11:40:55.000Z" title="Created 2022-04-01 19:40:55">2022-04-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/03/24/%E8%93%9D%E6%A1%A5%E6%9D%AFB%E7%BB%84-%E5%90%8E%E7%BC%80%E8%A1%A8%E8%BE%BE%E5%BC%8F/" title="蓝桥杯B组_后缀表达式"><img src="/media/las.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="蓝桥杯B组_后缀表达式"/></a><div class="content"><a class="title" href="/2022/03/24/%E8%93%9D%E6%A1%A5%E6%9D%AFB%E7%BB%84-%E5%90%8E%E7%BC%80%E8%A1%A8%E8%BE%BE%E5%BC%8F/" title="蓝桥杯B组_后缀表达式">蓝桥杯B组_后缀表达式</a><time datetime="2022-03-24T11:39:08.000Z" title="Created 2022-03-24 19:39:08">2022-03-24</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By duanqihang</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">蜀ICP备2021025306号-1</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/pluginsSrc/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'yzkCNT2NoQIDpQwERWjYnQWQ-gzGzoHsz',
      appKey: 'bEfJaAVnixoX5I4j2fTRQi47',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('/pluginsSrc/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="/pluginsSrc/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>